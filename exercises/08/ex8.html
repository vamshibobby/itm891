<!doctype html>

<html>
   <head>
      <meta charset="UTF-8"/>
      <link rel="stylesheet" type="text/css" href="ex8.css"/>
      <title>Exercise 8</title>
   <style>
    table, th, td { 
	border: 1px solid black;
    }
   </style
   </head>
	
   <body>
      <h1>Computer Vision</h1>

      <img alt="Identifying objects" src="cv_image.png">

      <p class="allpara"><b>Computer vision</b> is an interdisciplinary scientific field that deals with how <a href="https://en.wikipedia.org/wiki/Computer" title="Computers">computers</a> can gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to understand and automate tasks that the human visual system can do.</p>

      <p class="allpara">Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions.[4][5][6][7] Understanding in this context means the transformation of visual images (the input of the retina) into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory..</p>

      <p class="allpara">You can read more about computer vision <a href="https://en.wikipedia.org/wiki/Computer_vision" title="Computer Vision">here</a>.</p>

      <table style="width:100%"
	<tr>
	   <th colspan="3">Outstanding computer vision papers published in 2019</th>
	</tr>	  

	<tr>
	   <th>Paper Name</th>
	   <th>Author/s</th>
	   <th>Organization</th>	
	</tr>	

	<tr>
	   <th><a href="https://arxiv.org/abs/1905.11946v1" title="Paper1">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a></th>
	   <th>Mingxing Tan and Quoc V. Le</th>
	   <th>Google</th>
	</tr>	

	<tr>
	   <th><a href="https://arxiv.org/abs/1904.11111" title="Paper2">Learning the Depths of Moving People by Watching Frozen People</a></th>
	   <th>Zhengqi Li, Tali Dekel, Forrester Cole, Richard Tucker, Noah Snavely, Ce Liu, William T. Freeman</th>
	   <th>Google</th>
	</tr>	

	<tr>
	   <th><a href="https://arxiv.org/abs/1906.06423" title="Paper3">Fixing the Train-Test Resolution Discrepancy</a></th>
	   <th>Hugo Touvron, Andrea Vedaldi, Matthijs Douze, Hervé Jégou</th>
	   <th>Facebook</th>
	</tr>	
   </body>
</html>