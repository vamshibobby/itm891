{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 09: Web Scraping Wikipedia\n",
    "\n",
    "I would like you to examine whether or not there is a linear correlation between the size of a US state and the year it was admitted to the union.\n",
    "\n",
    "Objectives: \n",
    "+ Scraping a table from a webpage\n",
    "+ Storing that data in a dataframe\n",
    "+ Performing a linear regression on that data\n",
    "\n",
    "## Part A\n",
    "Using the URL I've provided below, I want you to scrape:\n",
    "1. The name of each state\n",
    "2. The year of admittance for each state\n",
    "3. The land area for each state\n",
    "\n",
    "Examine the URL to the webpage I've provided using your browser's element inspector to determine how to parse the relavent table.  \n",
    "\n",
    "Store the data collected in a Pandas' DataFrame.\n",
    "\n",
    "## Part B\n",
    "Once you have scraped the necessary data, I would like you to perform a linear regression on the year of admittance for each state (x-axis) against the land area of each state (y-axis) using the Linear Regression model from scikit learn.\n",
    "\n",
    "You may use the [API reference](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) and [this example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py) to assist you with your regression.\n",
    "\n",
    "Plot the data points and regression line.  Print out the coefficients, mean squared error, and $r^2$ values of this model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import scrapy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the html content using 'requests' package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6b2ef1bd1284>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "url='https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States'\n",
    "html = requests.get(url).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize three lists for states, year of admission and area\n",
    "* Get the tr/td elements as necessary\n",
    "* Clean the year and area lists\n",
    "* Create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list = []\n",
    "admin_list = []\n",
    "area_list = []\n",
    "for tri in sel.css(\"table\")[0].css('tbody tr')[2:]:\n",
    "    states_list.append(tri.css(\"th a::attr(title)\").extract()[0])\n",
    "    if len(tri.css(\"td\"))==12:\n",
    "        admin_list.append(tri.css(\"td\")[3].css(\"::text\").extract()[0])\n",
    "        area_list.append(tri.css(\"td\")[5].css(\"::text\").extract()[0])\n",
    "    else:\n",
    "        admin_list.append(tri.css(\"td\")[2].css(\"::text\").extract()[0])\n",
    "        area_list.append(tri.css(\"td\")[4].css(\"::text\").extract()[0])\n",
    "\n",
    "admin_list = [int(i.split(\", \")[1]) for i in admin_list]\n",
    "area_list = [int(i.split(\"\\n\")[0].replace(\",\",\"\")) for i in area_list]\n",
    "states = pd.DataFrame({\"State\":states_list,\"Year_of_admission\":admin_list,\"Area\":area_list})\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easier way to pull the datable using pandas inbuilt function \"read_html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = pd.read_html(url)\n",
    "states1 = tbl[0].iloc[:,[0,4,6]].copy()\n",
    "states1.columns = [\"State\",\"Year_of_admission\",\"Area\"]\n",
    "states1.Year_of_admission = states1.Year_of_admission.apply(lambda x:x.split(\", \")[1])\n",
    "states1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a linear regression model using sklearn and getting the coefficients, rsquare and mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(states[\"Year_of_admission\"]).reshape(-1,1)\n",
    "y = np.array(states[\"Area\"])\n",
    "model = linear_model.LinearRegression().fit(X, y)\n",
    "print(f\"The coefficient of the model is: {model.coef_}\")\n",
    "print(f\"R-square is: {model.score(X,y)}\")\n",
    "print(f\"Mean squared error is: {mean_squared_error(y,model.predict(X))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use statsmodels to get the p-values of the coefficient and hence get to know the statistical significance too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y,X2).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is <0.05 and hence the coefficient is significant\n",
    "\n",
    "Below is the plot that shows the linear trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,y,color=\"black\")\n",
    "plt.plot(X,model.predict(X),color=\"red\",linewidth = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only outliers are Alaska and Hawaii that got admitted pretty late but have very high and very less areas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
